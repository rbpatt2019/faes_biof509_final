{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# FAES_BIOF509_FINAL\n",
    "\n",
    "Predicting neurodegeneration from global proteomics\n",
    "\n",
    "Project based on the [_drivendata/cookiecutter-data-science_](https://github.com/drivendata/cookiecutter-data-science) project structure\n",
    "\n",
    "[![Code Style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/ambv/black)\n",
    "[![GPL License](https://badges.frapsoft.com/os/gpl/gpl.svg?v=103)](https://opensource.org/licenses/GPL-3.0/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Command line notebooks!\n",
    "\n",
    "Shout out to Martin's nbless package!\n",
    "\n",
    "```bash\n",
    "nbless notebooks/slides/slide_* -o notebooks/index.ipynb\n",
    "nbdeck notebooks/index.ipynb\n",
    "nbconv notebooks/index.ipynb -e slides -o index.html\n",
    "cp index.html reports/index.html\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Inspiration\n",
    "\"Global quantitative analysis of the human brain proteome in Alzheimer’s and Parkinson’s Disease\"\n",
    "doi:10.1038/sdata.2018.36\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Challenges\n",
    "\n",
    "1. Dimensionality - 40 samples (10 per group) and ~12000 features\n",
    "1. Data Wrangling - the published data is not in particularly great in structure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Plan\n",
    "\n",
    "1. Data wrangling\n",
    "1. Exploratory data visualisation - volcano plot, UMAP\n",
    "1. Dimensionality reduction/feature selection\n",
    "1. Machine learning - comparison between classification and clustering\n",
    "1. Validation - Leave-one-out, as sample is so small\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import umap\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "import src.data.CleanFrame as cf\n",
    "\n",
    "\n",
    "class CleanFrame(pd.core.frame.DataFrame):\n",
    "    \"\"\"Sub-classed DataFrame with expanded method for cleaning\n",
    "    \n",
    "    Frequently, when loading data, a number of cleaning steps are performed that do not have direct functions in the pandas module.\n",
    "    This class seeks to add those functionalities on top of pandas to expand its capacity\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    clean_cols: \n",
    "        Cleans column names by stripping white space, removing white space, and converting all characters to either lower or upper case\n",
    "    filter_by_val:\n",
    "        Select rows based on values in a given column\n",
    "    volcano:\n",
    "        Makes volcano plots\n",
    "    umap:\n",
    "        performs UMAP for dimension reduction and plots the results\n",
    "    \"\"\"\n",
    "\n",
    "    @property\n",
    "    def _constructor(self):\n",
    "        return CleanFrame\n",
    "\n",
    "    def clean_cols(\n",
    "        self,\n",
    "        strip=True,\n",
    "        spaces=True,\n",
    "        space_char=\"_\",\n",
    "        lower=True,\n",
    "        upper=False,\n",
    "        inplace=False,\n",
    "    ):\n",
    "        \"\"\"Cleans column names\n",
    "\n",
    "        Inputs\n",
    "        ------\n",
    "        strip: bool\n",
    "            default: True\n",
    "            Whether to strip leading and trailing whitespace\n",
    "        spaces: bool\n",
    "            default: True\n",
    "            Whether to replace spaces with space_char\n",
    "            Note that odd behaviour results if strip=True and spaces=False\n",
    "        space_char: str\n",
    "            default: '_'\n",
    "            If spaces=True, then ' ' will be replaced with this value\n",
    "        lower: bool\n",
    "            default: True\n",
    "            Whether to convert all letters to lower case\n",
    "            Note that odd behaviour will results if both lower=True and upper=True\n",
    "        upper: bool\n",
    "            default: False\n",
    "            Whether to convert all letters to upper case\n",
    "            Note that odd behaviour will results if both lower=True and upper=True\n",
    "        inplace: bool\n",
    "            If true, the operation occurs inplace, altering self.\n",
    "\n",
    "        Outputs\n",
    "        -------\n",
    "        new_data: CleanFrame\n",
    "            Only if inplace=False\n",
    "            The cleaned dataframe\n",
    "        \"\"\"\n",
    "\n",
    "        # Type check inputs\n",
    "        for i in (strip, spaces, lower, upper, inplace):\n",
    "            if not (isinstance(i, bool)):\n",
    "                raise ValueError(f\"{i} must be a bool\")\n",
    "        if not isinstance(space_char, str):\n",
    "            raise ValueError(\"space_char must be a str\")\n",
    "\n",
    "        # Operate\n",
    "        new_data = self.copy(deep=True)\n",
    "        if strip:\n",
    "            new_data.columns = new_data.columns.str.strip()\n",
    "        if spaces:\n",
    "            new_data.columns = new_data.columns.str.replace(\" \", space_char)\n",
    "        if lower:\n",
    "            new_data.columns = new_data.columns.str.lower()\n",
    "        if upper:\n",
    "            new_data.columns = new_data.columns.str.upper()\n",
    "\n",
    "        # self._update_inplace is from pandas.core.frame\n",
    "        if inplace:\n",
    "            self._update_inplace(new_data)\n",
    "        else:\n",
    "            return new_data\n",
    "\n",
    "    def filter_by_val(self, col=\"\", vals=[], keep=True, inplace=False):\n",
    "        \"\"\"Keeps rows of a dataframe based on value(s) in a column(s)\n",
    "\n",
    "        Inputs\n",
    "        ------\n",
    "        cols: str\n",
    "            column name to be used for filtering. col must be in self.columns\n",
    "        vals: list  \n",
    "            Values to search for in columns\n",
    "        keep: bool\n",
    "            If false, drop rows where vals are in cols\n",
    "            If true, drop rows where vals are NOT in cols\n",
    "        inplace: bool\n",
    "            If true, the operation occurs inplace, altering self.\n",
    "\n",
    "        Outputs\n",
    "        -------\n",
    "        new_data: CleanFrame\n",
    "            Only if inplace=False\n",
    "            The cleaned dataframe\n",
    "        \"\"\"\n",
    "\n",
    "        # Type check inputs\n",
    "        for i in (keep, inplace):\n",
    "            if not isinstance(i, bool):\n",
    "                raise ValueError(f\"{i} must be a bool\")\n",
    "        if not isinstance(col, str):\n",
    "            raise ValueError(\"col must be a str in self.columns\")\n",
    "        if not isinstance(vals, (list, tuple)):\n",
    "            raise ValueError(\"vals must be a list or tuple\")\n",
    "\n",
    "        # Operate, checking whether to keep or discard\n",
    "        if keep:\n",
    "            new_data = self[self[col].isin(vals)]\n",
    "        else:\n",
    "            new_data = self[~self[col].isin(vals)]\n",
    "\n",
    "        # self._update_inplace is from pandas.core.frame\n",
    "        if inplace:\n",
    "            self._update_inplace(new_data)\n",
    "        else:\n",
    "            return new_data\n",
    "\n",
    "    def volcano(\n",
    "        self,\n",
    "        x,\n",
    "        y,\n",
    "        is_log=True,\n",
    "        fold_cut=0.585,\n",
    "        q_cut=1.301,\n",
    "        title=\"Volcano Plot\",\n",
    "        title_size=12,\n",
    "        label_size=8,\n",
    "        show=True,\n",
    "        save=False,\n",
    "        path=\"reports/figures/volcano.png\",\n",
    "    ):\n",
    "\n",
    "        \"\"\"Makes a volcano plot of the data\n",
    "\n",
    "        Inputs\n",
    "        ------\n",
    "        x: str\n",
    "        Column name containing fold change values\n",
    "        y: str\n",
    "        Column name containing q_scores\n",
    "        is_log: bool, Optional\n",
    "        Whether or not the passed data has already had its log taken\n",
    "        If false, the appropriate log will be taken of both x and y\n",
    "        fold_cut: numeric, Optional\n",
    "        log2(fold_change) to consider significant\n",
    "        Default is fold_change greater than 1.5\n",
    "        fold_cut: numeric, Optional\n",
    "        -log10(q_score) to consider significant\n",
    "        Default is q_score less than 0.05\n",
    "        title: str, Optional\n",
    "        Plot title\n",
    "        title_size: numeric, Optional\n",
    "        Font size, in pts, to use for Figure title\n",
    "        label_size: numeric, Optional\n",
    "        Font size, in pts, to use for axes title\n",
    "        show: bool, Optional\n",
    "        If true, display the plot\n",
    "        save: bool, Optional\n",
    "        If true, save the plot\n",
    "        path: str, Optional\n",
    "        Where to save the plot, if save == True\n",
    "\n",
    "        Outputs\n",
    "        -------\n",
    "        \"\"\"\n",
    "\n",
    "        # Type check inputs\n",
    "        for i in (x, y, title, path):\n",
    "            if not isinstance(i, str):\n",
    "                raise ValueError(f\"{i} must be a str\")\n",
    "        for i in (is_log, show, save):\n",
    "            if not isinstance(i, bool):\n",
    "                raise ValueError(f\"{i} must be a bool\")\n",
    "        for var in (title_size, label_size):\n",
    "            try:\n",
    "                float(var)\n",
    "            except (ValueError, TypeError) as err:\n",
    "                print(f\"{var} needs to be numeric\")\n",
    "                raise\n",
    "\n",
    "        # Log, if necessary\n",
    "        if not is_log:\n",
    "            x, y = np.log2(self[x]), -np.log10(self[y])\n",
    "        else:\n",
    "            x, y = self[x], self[y]\n",
    "\n",
    "        # Create red, black green custom color map\n",
    "        cmap = LinearSegmentedColormap.from_list(\n",
    "            \"Volcano\", [(1, 0, 0), (0, 0, 0), (0, 1, 0)], N=3\n",
    "        )\n",
    "\n",
    "        # Establish colors\n",
    "        conditions = [(y >= q_cut) & (x >= fold_cut), (y >= q_cut) & (x <= -fold_cut)]\n",
    "        choices = [2, 0]\n",
    "        colors = np.select(conditions, choices, default=1)\n",
    "\n",
    "        # Plot data\n",
    "        plt.scatter(x, y, c=colors, cmap=cmap, s=2, alpha=0.7)\n",
    "        plt.axvline(fold_cut, linestyle=\"--\", color=\"gray\", linewidth=1)\n",
    "        plt.axvline(-fold_cut, linestyle=\"--\", color=\"gray\", linewidth=1)\n",
    "        plt.axhline(q_cut, linestyle=\"--\", color=\"gray\", linewidth=1)\n",
    "\n",
    "        # Plot settings\n",
    "        sns.despine(offset=5, trim=False)\n",
    "        plt.title(title, fontdict={\"fontsize\": title_size}, pad=15)\n",
    "        plt.gca().set_aspect(\"equal\", \"datalim\")\n",
    "        cbar = plt.colorbar(\n",
    "            boundaries=np.arange(4) - 0.5, ticks=np.arange(3), shrink=0.33\n",
    "        )\n",
    "        cbar.ax.set_yticklabels(\n",
    "            [\"Sig. Under\", \"N.S.\", \"Sig. Over\"], fontdict={\"fontsize\": label_size}\n",
    "        )\n",
    "        plt.xlabel(\"log2(fold_change)\", fontdict={\"fontsize\": label_size}, labelpad=5)\n",
    "        plt.ylabel(\"-log10(q_score)\", fontdict={\"fontsize\": label_size}, labelpad=10)\n",
    "        plt.tick_params(axis=\"both\", labelsize=label_size)\n",
    "\n",
    "        # Show or save\n",
    "        if save:\n",
    "            plt.savefig(path, dpi=600)\n",
    "        if show:\n",
    "            plt.show()\n",
    "\n",
    "    def umap(\n",
    "        self,\n",
    "        X_list,\n",
    "        y_name,\n",
    "        plt_comp=(0, 1),\n",
    "        title=\"UMAP Plot\",\n",
    "        title_size=12,\n",
    "        label_size=8,\n",
    "        show=True,\n",
    "        save=False,\n",
    "        path=\"report/figures/umap.png\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"Makes a UMAP plot of the data\n",
    "\n",
    "        Inputs\n",
    "        ------\n",
    "        X_list: iterable\n",
    "            List of columns to be used as features\n",
    "        y_name: str\n",
    "            Column containing labels\n",
    "        plt_comp: tuple\n",
    "            Dimensions to be plotted\n",
    "        title: str, Optional\n",
    "            Plot title\n",
    "        title_size: numeric, Optional\n",
    "            Font size, in pts, to use for Figure title\n",
    "        label_size: numeric, Otional\n",
    "            Font size, in pts, to use for axes title\n",
    "        show: bool, Optional\n",
    "            If true, display the plot\n",
    "        save: bool, Optional\n",
    "            If true, save the plot\n",
    "        path: str, Optional\n",
    "            Where to save the plot, if save == True\n",
    "        kwargs:\n",
    "            Additional parameters to be passed to umap.UMAP()\n",
    "\n",
    "        Outputs\n",
    "        -------\n",
    "        \"\"\"\n",
    "        # Type check inputs\n",
    "        for i in (y_name, title, path):\n",
    "            if not isinstance(i, str):\n",
    "                raise ValueError(f\"{i} must be a str\")\n",
    "        for i in (save, show):\n",
    "            if not isinstance(i, bool):\n",
    "                raise ValueError(f\"{i} must be a bool\")\n",
    "        for var in (title_size, label_size):\n",
    "            try:\n",
    "                float(var)\n",
    "            except (ValueError, TypeError) as err:\n",
    "                print(f\"{var} needs to be numeric\")\n",
    "                raise\n",
    "        if not isinstance(plt_comp, tuple):\n",
    "            raise ValueError(f'plt_comp must be a tuple')\n",
    "\n",
    "        # Reducer for umap\n",
    "        X, y = self[X_list], self[y_name]\n",
    "        reducer = umap.UMAP(random_state=1, **kwargs)\n",
    "        embedding = reducer.fit_transform(X)\n",
    "\n",
    "        # Create conditions/choices for colors, leave first for default\n",
    "        choices = np.arange(1, len(y.unique()))\n",
    "        conditions = [y == item for item in y.unique()[1:]]\n",
    "\n",
    "        # Plot UMAP\n",
    "        plt.scatter(\n",
    "            embedding[:, plt_comp[0]],\n",
    "            embedding[:, plt_comp[1]],\n",
    "            s=5,\n",
    "            c=np.select(conditions, choices, 0),\n",
    "            cmap=\"Spectral\",\n",
    "        )\n",
    "\n",
    "        # Plot settings\n",
    "        sns.despine(offset=5, trim=False)\n",
    "        plt.title(title, fontdict={\"fontsize\": title_size}, pad=15)\n",
    "        plt.gca().set_aspect(\"equal\", \"datalim\")\n",
    "        cbar = plt.colorbar(\n",
    "            boundaries=np.arange(len(y.unique()) + 1) - 0.5,\n",
    "            ticks=np.arange(len(y.unique())),\n",
    "            shrink=0.33,\n",
    "        )\n",
    "        cbar.ax.set_yticklabels(list(y.unique()), fontdict={\"fontsize\": label_size})\n",
    "\n",
    "        # Show or save\n",
    "        if save:\n",
    "            plt.savefig(path, dpi=600)\n",
    "        if show:\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import src.data.CleanFrame as cf\n",
    "\n",
    "\n",
    "def make_data(\n",
    "    files, usecols=None, names=None, index_col=None, axis=0, join=\"outer\", keys=None\n",
    "):\n",
    "    # Type check files\n",
    "    if not isinstance(files, str):\n",
    "        raise ValueError(f\"files must be a str, not {type(files)}\")\n",
    "    # Find files\n",
    "    paths = glob.iglob(files)\n",
    "    # Read in files, sep=None with engine='python' will auto determine delim\n",
    "    reads = (\n",
    "        pd.read_csv(\n",
    "            file,\n",
    "            usecols=usecols,\n",
    "            header=0,\n",
    "            names=names,\n",
    "            index_col=index_col,\n",
    "            sep=None,\n",
    "            engine=\"python\",\n",
    "        )\n",
    "        for file in paths\n",
    "    )\n",
    "    # Convert to CleanFrame\n",
    "    cfs = (cf.CleanFrame(i) for i in reads)\n",
    "    # Clean data\n",
    "    clean = (i.prep_data() for i in cfs)\n",
    "    # Create final CleanFrame\n",
    "    data = cf.CleanFrame(\n",
    "        pd.concat(clean, axis=axis, join=join, keys=keys, sort=False, copy=False)\n",
    "    )\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Frontal_volcano_plot](reports/figures/Frontal_mean_ad.png) ![Frontal_volcano_plot](reports/figures/Frontal_mean_adpd.png) ![Frontal_volcano_plot](reports/figures/Frontal_mean_pd.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Cingulate_volcano_plot](reports/figures/Cingulate_mean_ad.png) ![Cingulate_volcano_plot](reports/figures/Cingulate_mean_adpd.png) ![Cingulate_volcano_plot](reports/figures/Cingulate_mean_pd.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![UMAP frontal](reports/figures/Frontal_label.png) ![UMAP cingulate](reports/figures/Cingulate_label.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![UMAP frontal](reports/figures/Frontal_batch.png) ![UMAP cingulate](reports/figures/Cingulate_batch.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![UMAP frontal](reports/figures/Frontal_batch_23.png) ![UMAP cingulate](reports/figures/Cingulate_batch_23.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![UMAP frontal](reports/figures/Frontal_sum_umap.png) ![UMAP cingulate](reports/figures/Cingulate_sum_umap.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## And That's it...so far!\n",
    "\n",
    "- Batch effect removal\n",
    "- Model selection wit yellowbricks classification report\n",
    "- Model tuning - gridsearchcv, but also yellowbrick\n",
    "   - Confusion matrix, ROCAUC, Precision-Recall, Validation Curve, Learning Curve\n",
    "- Refactoring!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
